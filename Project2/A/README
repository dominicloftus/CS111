NAME: Dominic Loftus
EMAIL: dominicloftus@yahoo.com
ID: 204910863

FILES

lab2_add.c: source file that runs multithreaded additions operations

SortedList.h: header file for SortedList.c

SortedList.c: implements sorted doubly linked list with insert, delete,
lookup, and length options

lab2_list.c: source file that runs multithreaded linked list operations

lab2_add.csv: standard output from lab2_add.c, used in plotting graphs with
lab2_add.gp

lab2_list.csv: standard output from lab2_list.c, used in plotting graphs with
lab2_list.gp

lab2_add.gp: used with gnuplot to generate graphs from lab2_add.c

lab2_list.gp: used with gnuplot to generate graphs from lab2_list.c

GRAPHS

lab2_add-1.png: plots threads and iterations that run without failing both
with and without yields

lab2_add-2.png: plots cost per oprations vs iterations to show the different
cost between yielding and not yielding

lab2_add-3.png: plots cost per operation vs iteration with a single thread
to show decreasing cost with more operations

lab2_add-4.png: plots iterations per thread and threads to show which
combination of synchronization run without failing

lab2_add-5.png: plots cost per operations vs threads to show how different
synchronization methods cost grow with more threads

lab2_list-1.png: plots cost per operation vs iterations to show relationship
between them

lab2_list-2.png: plots iterations and threads with different yield options
to show which are able to run successfully

lab2_list-3.png: shows different iterations, yields and lock combinations
to show which are able to successfully protect the threads

lab2_list-4.png: plots cost per operations vs threads to show how different
synchronization	methods	cost grow with more threads

Makefile:
default: compiles lab2_add.c and lab2_list.c into their executables
build: default option
tests: runs lab2_add and lab2_list over 200 times with different inputs
to generate data to be used in graphs
graphs: uses gnuplot to generate .png graphs
dist: builds deliverable tarball
clean: removes tarball and executable files





ANSWERS

2.1.1
It takes many iterations because during every iteration there is a chance for a
context switch to another thread to occur which could result in errors appearing
due to the race condition. The probability of a context switch occurring grows
with each iteration, requiring many iterations for an error to be seen.

A significantly smaller number of iterations rarely fails because it's very unlikely
that a context switch will occur in this amount of time and the scheduler will
probably let each thread finish before switching.


2.1.2
The --yield runs are so much slower because every iteration there is a context
switch to another thread which takes a lot of time.

The additional time goes into context switching.

It is not possible to get valid per-operations timings because so much time goes
into context switching that it doesn't accurately represent the time of the operations.


2.1.3
Cost per operations drops with increasing iterations because each iteration is very
fast, however the cost of creating each thread is expensive, but stays constant
with increasing iterations. So the more iterations run with the same number of
threads will lead to a lower cost per operation.

The cost per iteration drops rapidly for smaller iterations, however begins to plateau
at larger iterations, once the function is seemingly stable or flat that is how many
you should run.

2.1.4
They all perform similarly for low numbers of threads because there will be less time
spent creating threads and switching between threads which is where most of the runtime
comes from. So with less threads their runtimes will be closer.

The three protected operations slow down with the growing number of threads because
scheduler will switch to other locked threads at points which causes a lot of waiting
for locks to be released and this time grows with a growing number of threads.


2.2.1
For part 1, the time per mutex protected operation grew from using
one thread to four threads however after that point began to plateau and
stopped growing. For part 2 the mutex protected time stayed constant
as the number of threads grew.
This is because when list operations are performed they take a much longer
time than the add operations so the scheduler will allow them to run for
longer. This results in less switching between threads relative to the time
spent running operations. This shows itself with the growing cost of mutex
protected operations in the beginning of part 1, but growth slows down a lot
with larger numbers of threads.

2.2.2
Both the mutex and spin lock seem to function about the same for lower numbers
of threads however as the number of threads increase, the mutex increases
slightly then plateaus in its cost per operation. The spin lock however
seems to grow exponentially with increasing number of threads with no sign
of slowing down with higher number of theads. 
This is because a spin lock with never block and will waste time continually
checking to see if the lock was released which wastes a lot of time especially
with a large number of threads. The mutex however will cause blocking to
occur making the scheduler ignore the locked thread until the lock is released.