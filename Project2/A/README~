NAME: Dominic Loftus
EMAIL: dominicloftus@yahoo.com
ID: 204910863

FILES

lab2_add.c 







ANSWERS

2.1.1
It takes many iterations because during every iteration there is a chance for a
context switch to another thread to occur which could result in errors appearing
due to the race condition. The probability of a context switch occurring grows
with each iteration, requiring many iterations for an error to be seen.

A significantly smaller number of iterations rarely fails because it's very unlikely
that a context switch will occur in this amount of time and the scheduler will
probably let each thread finish before switching.


2.1.2
The --yield runs are so much slower because every iteration there is a context
switch to another thread which takes a lot of time.

The additional time goes into context switching.

It is not possible to get valid per-operations timings because so much time goes
into context switching that it doesn't accurately represent the time of the operations.


2.1.3
Cost per operations drops with increasing iterations because each iteration is very
fast, however the cost of creating each thread is expensive, but stays constant
with increasing iterations. So the more iterations run with the same number of
threads will lead to a lower cost per operation.

The cost per iteration drops rapidly for smaller iterations, however begins to plateau
at larger iterations, once the function is seemingly stable or flat that is how many
you should run.

2.1.4
They all perform similarly for low numbers of threads because there will be less time
spent creating threads and switching between threads which is where most of the runtime
comes from. So with less threads their runtimes will be closer.

The three protected operations slow down with the growing number of threads because
scheduler will switch to other locked threads at points which causes a lot of waiting
for locks to be released and this time grows with a growing number of threads.


2.2.1
For part 1, the time per mutex protected operation grew from using
one thread to four threads however after that point began to plateau and
stopped growing. For part 2 the mutex protected time stayed constant
as the number of threads grew.
This is because when list operations are performed they take a much longer
time than the add operations so the scheduler will allow them to run for
longer. This results in less switching between threads relative to the time
spent running operations. This shows itself with the growing cost of mutex
protected operations in the beginning of part 1, but growth slows down a lot
with larger numbers of threads.

2.2.2
Both the mutex and spin lock seem to function about the same for lower numbers
of threads however as the number of threads increase, the mutex increases
slightly then plateaus in its cost per operation. The spin lock however
seems to grow exponentially with increasing number of threads with no sign
of slowing down with higher number of theads. 
This is because a spin lock with never block and will waste time continually
checking to see if the lock was released which wastes a lot of time especially
with a large number of threads. The mutex however will cause blocking to
occur making the scheduler ignore the locked thread until the lock is released.